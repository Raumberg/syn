package processor

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"strings"
)

// HuggingFaceProcessor –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Hugging Face Datasets
type HuggingFaceProcessor struct {
	id             string
	pythonPath     string
	tempDir        string
	datasetName    string
	split          string
	streamable     bool
	limit          int
	offset         int
	filters        map[string]interface{}
	numericFilters map[string]NumericFilter
	fields         []string
	extraArgs      map[string]string
	debug          bool
}

// NumericFilter –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
type NumericFilter struct {
	Min      float64
	Max      float64
	Operator string
}

// NewHuggingFaceProcessor —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è Hugging Face
func NewHuggingFaceProcessor(
	id string,
	pythonPath string,
	tempDir string,
	datasetName string,
	split string,
	streamable bool,
	filters map[string]interface{},
	fields []string,
) *HuggingFaceProcessor {
	if pythonPath == "" {
		pythonPath = "python3" // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º python3
	}

	if split == "" {
		split = "train" // –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä–µ–º train split
	}

	return &HuggingFaceProcessor{
		id:             id,
		pythonPath:     pythonPath,
		tempDir:        tempDir,
		datasetName:    datasetName,
		split:          split,
		streamable:     streamable,
		limit:          0, // 0 –æ–∑–Ω–∞—á–∞–µ—Ç –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
		offset:         0,
		filters:        filters,
		numericFilters: make(map[string]NumericFilter),
		fields:         fields,
		extraArgs:      make(map[string]string),
		debug:          false,
	}
}

// ID –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
func (p *HuggingFaceProcessor) ID() string {
	return p.id
}

// SetLimit —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ª–∏–º–∏—Ç –¥–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
func (p *HuggingFaceProcessor) SetLimit(limit int) *HuggingFaceProcessor {
	p.limit = limit
	return p
}

// SetOffset —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è –≤—ã–±–æ—Ä–∫–∏
func (p *HuggingFaceProcessor) SetOffset(offset int) *HuggingFaceProcessor {
	p.offset = offset
	return p
}

// AddNumericFilter –¥–æ–±–∞–≤–ª—è–µ—Ç —á–∏—Å–ª–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä
func (p *HuggingFaceProcessor) AddNumericFilter(field string, min, max float64, operator string) *HuggingFaceProcessor {
	p.numericFilters[field] = NumericFilter{
		Min:      min,
		Max:      max,
		Operator: operator,
	}
	return p
}

// AddExtraArg –¥–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç –¥–ª—è Python-—Å–∫—Ä–∏–ø—Ç–∞
func (p *HuggingFaceProcessor) AddExtraArg(key, value string) *HuggingFaceProcessor {
	p.extraArgs[key] = value
	return p
}

// Process –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ
func (p *HuggingFaceProcessor) Process(ctx context.Context, data interface{}) (interface{}, error) {
	return p.loadDatasetFromHF(ctx)
}

// loadDatasetFromHF –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Hugging Face –∏—Å–ø–æ–ª—å–∑—É—è Python
func (p *HuggingFaceProcessor) loadDatasetFromHF(ctx context.Context) (interface{}, error) {
	// –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π Python-—Å–∫—Ä–∏–ø—Ç
	scriptPath, err := p.createPythonScript()
	if err != nil {
		return nil, fmt.Errorf("–Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å Python-—Å–∫—Ä–∏–ø—Ç: %w", err)
	}
	defer os.Remove(scriptPath)

	if p.debug {
		fmt.Printf("üêç –°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç Python: %s\n", scriptPath)
	}

	// –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
	outputPath := filepath.Join(p.tempDir, fmt.Sprintf("hf_dataset_%s.json", p.id))
	defer os.Remove(outputPath)

	if p.debug {
		fmt.Printf("üìÑ –í—Ä–µ–º–µ–Ω–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: %s\n", outputPath)
	}

	// –ó–∞–ø—É—Å–∫–∞–µ–º Python-—Å–∫—Ä–∏–ø—Ç
	cmd := exec.CommandContext(ctx, p.pythonPath, scriptPath, "--output", outputPath,
		"--dataset", p.datasetName, "--split", p.split)

	if p.streamable {
		cmd.Args = append(cmd.Args, "--streamable")
	}

	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –∏ —Å–º–µ—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–∏ —É–∫–∞–∑–∞–Ω—ã
	if p.limit > 0 {
		cmd.Args = append(cmd.Args, "--limit", fmt.Sprintf("%d", p.limit))
	}

	if p.offset > 0 {
		cmd.Args = append(cmd.Args, "--offset", fmt.Sprintf("%d", p.offset))
	}

	// –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –≤ –≤–∏–¥–µ JSON
	if len(p.filters) > 0 {
		filtersJSON, err := json.Marshal(p.filters)
		if err != nil {
			return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ –º–∞—Ä—à–∞–ª–ª–∏–Ω–≥–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤: %w", err)
		}
		cmd.Args = append(cmd.Args, "--filters", string(filtersJSON))

		if p.debug {
			fmt.Printf("üîç –§–∏–ª—å—Ç—Ä—ã: %s\n", string(filtersJSON))
		}
	}

	// –î–æ–±–∞–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
	if len(p.numericFilters) > 0 {
		numFiltersJSON, err := json.Marshal(p.numericFilters)
		if err != nil {
			return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ –º–∞—Ä—à–∞–ª–ª–∏–Ω–≥–∞ —á–∏—Å–ª–æ–≤—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤: %w", err)
		}
		cmd.Args = append(cmd.Args, "--numeric-filters", string(numFiltersJSON))

		if p.debug {
			fmt.Printf("üî¢ –ß–∏—Å–ª–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã: %s\n", string(numFiltersJSON))
		}
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è
	if len(p.fields) > 0 {
		cmd.Args = append(cmd.Args, "--fields", strings.Join(p.fields, ","))

		if p.debug {
			fmt.Printf("üè∑Ô∏è –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–ª—è: %s\n", strings.Join(p.fields, ","))
		}
	}

	// –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
	for k, v := range p.extraArgs {
		cmd.Args = append(cmd.Args, fmt.Sprintf("--%s", k), v)
	}

	// –î–æ–±–∞–≤–ª—è–µ–º verbose —Ä–µ–∂–∏–º, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –æ—Ç–ª–∞–¥–∫–∞
	if p.debug {
		cmd.Args = append(cmd.Args, "--verbose")
	}

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	if p.debug {
		fmt.Printf("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–∞–Ω–¥—ã: %s\n", strings.Join(cmd.Args, " "))
	}

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Python-—Å–∫—Ä–∏–ø—Ç–∞: %w\nSTDOUT: %s\nSTDERR: %s", err, stdout.String(), stderr.String())
	}

	// –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ stdout —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏
	stdoutStr := stdout.String()
	if stdoutStr != "" && p.debug {
		fmt.Printf("üìù Python stdout: %s\n", stdoutStr)
	}

	// –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
	if _, err := os.Stat(outputPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω: %s\nSTDOUT: %s\nSTDERR: %s", outputPath, stdout.String(), stderr.String())
	}

	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: %w", err)
	}

	if p.debug {
		fmt.Printf("üìä –†–∞–∑–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: %s\n", humanizeBytes(int64(len(data))))
	}

	if len(data) == 0 {
		return nil, fmt.Errorf("–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –ø—É—Å—Ç: %s\nSTDOUT: %s\nSTDERR: %s", outputPath, stdout.String(), stderr.String())
	}

	// –ü–∞—Ä—Å–∏–º JSON
	var result []map[string]interface{}
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: %w\nData: %s", err, string(data))
	}

	if p.debug {
		fmt.Printf("‚úÖ –ü–æ–ª—É—á–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n", len(result))
		if len(result) > 0 {
			fmt.Printf("üîç –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤–æ–π –∑–∞–ø–∏—Å–∏:\n")
			printMapPreview(result[0], 3)
		}
	}

	return result, nil
}

// humanizeBytes –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –±–∞–π—Ç—ã –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç
func humanizeBytes(bytes int64) string {
	const unit = 1024
	if bytes < unit {
		return fmt.Sprintf("%d B", bytes)
	}
	div, exp := int64(unit), 0
	for n := bytes / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(bytes)/float64(div), "KMGTPE"[exp])
}

// printMapPreview –≤—ã–≤–æ–¥–∏—Ç —á–∞—Å—Ç—å –∫–∞—Ä—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
func printMapPreview(m map[string]interface{}, maxItems int) {
	fmt.Println("  {")
	i := 0
	for k, v := range m {
		if i >= maxItems {
			fmt.Println("    ...")
			break
		}

		var valueStr string
		switch val := v.(type) {
		case string:
			if len(val) > 50 {
				valueStr = fmt.Sprintf("%q...", val[:50])
			} else {
				valueStr = fmt.Sprintf("%q", val)
			}
		case []interface{}:
			if len(val) > 3 {
				valueStr = fmt.Sprintf("[%v, %v, %v, ...]", val[0], val[1], val[2])
			} else {
				valueStr = fmt.Sprintf("%v", val)
			}
		default:
			valueStr = fmt.Sprintf("%v", val)
		}

		fmt.Printf("    %q: %s,\n", k, valueStr)
		i++
	}
	fmt.Println("  }")
}

// createPythonScript —Å–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π Python-—Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞
func (p *HuggingFaceProcessor) createPythonScript() (string, error) {
	script := `
import json
import argparse
from datasets import load_dataset
import numpy as np
import sys

def apply_numeric_filter(dataset, field, filter_config):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —á–∏—Å–ª–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä –∫ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    min_value = filter_config.get('Min', -float('inf'))
    max_value = filter_config.get('Max', float('inf'))
    operator = filter_config.get('Operator', '')
    
    if operator == 'gte':
        return dataset.filter(lambda x: x[field] >= min_value)
    elif operator == 'lte':
        return dataset.filter(lambda x: x[field] <= max_value)
    elif operator == 'gt':
        return dataset.filter(lambda x: x[field] > min_value)
    elif operator == 'lt':
        return dataset.filter(lambda x: x[field] < max_value)
    elif operator == 'eq':
        if min_value != -float('inf'):
            return dataset.filter(lambda x: x[field] == min_value)
        return dataset
    elif min_value > -float('inf') and max_value < float('inf'):
        return dataset.filter(lambda x: min_value <= x[field] <= max_value)
    elif min_value > -float('inf'):
        return dataset.filter(lambda x: x[field] >= min_value)
    elif max_value < float('inf'):
        return dataset.filter(lambda x: x[field] <= max_value)
    else:
        return dataset

def main():
    parser = argparse.ArgumentParser(description='Load a dataset from Hugging Face')
    parser.add_argument('--output', required=True, help='Output file path')
    parser.add_argument('--dataset', required=True, help='Dataset name')
    parser.add_argument('--split', default='train', help='Dataset split')
    parser.add_argument('--streamable', action='store_true', help='Load dataset in streaming mode')
    parser.add_argument('--filters', default='{}', help='Filters as JSON')
    parser.add_argument('--numeric-filters', default='{}', help='Numeric filters as JSON')
    parser.add_argument('--fields', help='Comma-separated list of fields to include')
    parser.add_argument('--limit', type=int, default=0, help='Maximum number of examples')
    parser.add_argument('--offset', type=int, default=0, help='Offset to start from')
    parser.add_argument('--shuffle', action='store_true', help='Shuffle the dataset')
    parser.add_argument('--seed', type=int, default=42, help='Random seed for shuffling')
    parser.add_argument('--verbose', action='store_true', help='Verbose output')
    
    args, unknown = parser.parse_known_args()
    
    try:
        # –ü–∞—Ä—Å–∏–º —Ñ–∏–ª—å—Ç—Ä—ã –∏–∑ JSON
        filters = json.loads(args.filters)
        numeric_filters = json.loads(args.numeric_filters)
        
        if args.verbose:
            print(f"Loading dataset: {args.dataset} (split: {args.split})")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        dataset = load_dataset(args.dataset, split=args.split, streaming=args.streamable)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
        if args.fields:
            fields = args.fields.split(',')
            dataset = dataset.select_columns(fields)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        if filters:
            def filter_func(x):
                for k, v in filters.items():
                    if k not in x or x[k] != v:
                        return False
                return True
            
            dataset = dataset.filter(filter_func)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        for field, filter_config in numeric_filters.items():
            if field not in dataset.column_names:
                if args.verbose:
                    print(f"Warning: Field {field} not found in dataset")
                continue
            
            dataset = apply_numeric_filter(dataset, field, filter_config)
        
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.shuffle and not args.streamable:
            dataset = dataset.shuffle(seed=args.seed)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ –∏ –ª–∏–º–∏—Ç
        if args.offset > 0 and not args.streamable:
            dataset = dataset.skip(args.offset)
        
        if args.limit > 0:
            dataset = dataset.take(args.limit)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        result = []
        for item in dataset:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã
            item_dict = {}
            for k, v in item.items():
                if isinstance(v, np.integer):
                    item_dict[k] = int(v)
                elif isinstance(v, np.floating):
                    item_dict[k] = float(v)
                elif isinstance(v, np.ndarray):
                    item_dict[k] = v.tolist()
                else:
                    item_dict[k] = v
            result.append(item_dict)
        
        if args.verbose:
            print(f"Processed {len(result)} examples")
        
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        if args.verbose:
            print(f"Saved {len(result)} examples to {args.output}")
    
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()
`

	// –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
	tmpFile, err := os.CreateTemp(p.tempDir, "hf_script_*.py")
	if err != nil {
		return "", err
	}
	defer tmpFile.Close()

	if _, err := tmpFile.WriteString(script); err != nil {
		return "", err
	}

	return tmpFile.Name(), nil
}

// LoadFromHuggingFace –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ Hugging Face
func LoadFromHuggingFace(
	ctx context.Context,
	pythonPath string,
	datasetName string,
	split string,
	streamable bool,
	filters map[string]interface{},
	fields []string,
) ([]map[string]interface{}, error) {
	processor := NewHuggingFaceProcessor(
		"hf_loader",
		pythonPath,
		os.TempDir(),
		datasetName,
		split,
		streamable,
		filters,
		fields,
	)

	result, err := processor.Process(ctx, nil)
	if err != nil {
		return nil, err
	}

	return result.([]map[string]interface{}), nil
}

// SetDebug —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏
func (p *HuggingFaceProcessor) SetDebug(debug bool) {
	p.debug = debug
}
